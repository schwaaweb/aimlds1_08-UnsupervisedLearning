{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "[Lecture](https://youtu.be/2qOL45sp75c)\n",
    "\n",
    "\n",
    "[View in Colaboratory](https://colab.research.google.com/github/schwaaweb/aimlds1_08-UnsupervisedLearning/blob/master/W08_CC--DJ--Coding_Challenge_Association_Models.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E3zcH1mQppxI"
   },
   "source": [
    "**Coding Challenge**\n",
    "\n",
    "In this coding challenge, you will apply the concepts of Association Rule Learning\n",
    "\n",
    "1) Utilize the Apriori Algorithm to uncover frequent itemsets \n",
    "\n",
    "2) Discover the strongest association rules that have high lift and high confidence\n",
    "\n",
    "3) Create a Directed Graph to surface the association rules identified in Step 2 above\n",
    "\n",
    "**Resources**:\n",
    "\n",
    "- The Wikipedia articles for [association rule learning](https://en.wikipedia.org/wiki/Association_rule_learning) and the [Apriori algorithm](https://en.wikipedia.org/wiki/Apriori_algorithm) provide a good introduction and overview of the topic.\n",
    "- The `mlxtend` package provides an [implementation of Apriori](http://rasbt.github.io/mlxtend/user_guide/frequent_patterns/apriori/) ([source code](https://github.com/rasbt/mlxtend/blob/master/mlxtend/frequent_patterns/apriori.py)) - it is encouraged to read and understand the documentation and code, so you can be a savvy user of it.\n",
    "- The `networkx` package has a [tutorial for drawing a directed graph](https://networkx.github.io/documentation/networkx-1.10/tutorial/index.html).\n",
    "\n",
    "\n",
    "**Dataset: ** The data you will utilize is from the **UCI Machine Learning Repository** and represents transactional data from a UK retailer from 2010 through 2011. The data set represents sales to wholesalers so it is slightly different from data representing customer purchase patterns but is still a useful data set for the purposes of this exercise.\n",
    "\n",
    "The data set can be downloaded from: http://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online%20Retail.xlsx\n",
    "\n",
    "**Guidance for coding challenge**:\n",
    "\n",
    "1) Focus on the data for the following 2 countries: 1) **Germany** and 2) **Belgium**. Go through the 3 steps highlighted above for each of the 2 countries. This analysis will enable you to compare/constrast the sales of frequent itemsets in the \"Germany\" from that in \"Belgium\"\n",
    "\n",
    "2) You will need to prepare the data. For example: some of the invoices contact 'C' in front of the invoice number; these ivoices should be removed from the dataset\n",
    "\n",
    "3) Product descriptions with a value of 'POSTAGE' in it will need to be treated since it could negatively skew/impact the results\n",
    "\n",
    "4) You will have to transpose the data set so that you get a proper representation of the underlying data set that can be feed into the Apriori Algorithm\n",
    "\n",
    "*Hint:* Good Reference while exploring your data set - https://medium.com/@msalmon00/helpful-python-code-snippets-for-data-exploration-in-pandas-b7c5aed5ecb9\n",
    "\n",
    "**Communicate your findings**:\n",
    "\n",
    "One of the common tasks for Data Scientists in the real world is to communicate their findings. Summarize your analysis and make recomendations on how you could potentially improve/bolster sales for the Online Retailer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%bash\n",
    "#conda install -c conda-forge mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget -c http://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online%20Retail.xlsx\n",
    "#!mv Online\\ Retail.xlsx Online_Retail.xlsx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import OnehotTransactions, TransactionEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = pd.read_excel('Online_Retail.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any nulls\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the nulls\n",
    "df.dropna(subset=['Description','CustomerID'], how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop('POSTAGE', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nulls are gone\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many contract invoices in the dataframe?\n",
    "df['InvoiceNo'].str.startswith('c').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove entries that start with 'c'\n",
    "df['InvoiceNo'] = df['InvoiceNo'].astype('str')\n",
    "df = df[~df['InvoiceNo'].str.startswith('C')]\n",
    "df['InvoiceNo'] = df['InvoiceNo'].astype('int')\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### German Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_per_row = df [df['Country']=='Germany'].pivot_table(index='InvoiceNo',columns='Description', values='Quantity',aggfunc='sum',fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_per_row.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now Drop 'POSTAGE'\n",
    "transactions_per_row.drop('POSTAGE', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "purchase_sets = transactions_per_row.applymap(lambda quantity: 1 if quantity >= 1 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_sets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets = apriori(purchase_sets, min_support=0.05, use_colnames=True)\n",
    "association_rules(frequent_itemsets, metric='confidence', min_threshold=0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "association_rules(frequent_itemsets, metric='lift', min_threshold=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_per_row(feature, value_of_feature,min_support,metric,min_threshold):\n",
    "    transactions_per_row = df [\n",
    "                                df[ feature ]== value_of_feature\n",
    "                              ].pivot_table(\n",
    "                                            index='InvoiceNo',\n",
    "                                            columns='Description', \n",
    "                                            values='Quantity',\n",
    "                                            aggfunc='sum',\n",
    "                                            fill_value=0\n",
    "                                            )\n",
    "    transactions_per_row.drop('POSTAGE', inplace=True, axis=1)\n",
    "    purchase_sets = transactions_per_row.applymap(lambda quantity: 1 if quantity >= 1 else 0)\n",
    "    frequent_itemsets = apriori(purchase_sets, min_support=min_support, use_colnames=True)\n",
    "    return association_rules(frequent_itemsets, metric=metric, min_threshold=min_threshold)\n",
    "    \n",
    "\n",
    "german_tpr = trans_per_row('Country','Germany',0.05,'confidence',0.08)\n",
    "german_tpr\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "german_tpr = trans_per_row('Country','Germany',0.05,'confidence',0.08)\n",
    "german_tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "german_tpr = trans_per_row('Country','Germany',0.05,'lift',4); german_tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "belgium_tpr = trans_per_row('Country','Belgium',0.05,'lift',18); belgium_tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "belgium_tpr = trans_per_row('Country','Belgium',0.05,'confidence',0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "belgium_tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as netx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_association_graph(rules, rules_to_show):\n",
    "  \"\"\"Function to draw graph visualization association rules.\"\"\"\n",
    "  DiGraph = netx.DiGraph()\n",
    "  \n",
    "  colors = np.random.rand(rules_to_show)\n",
    "  rule_nodes = set()\n",
    "  \n",
    "  for i in range(rules_to_show):\n",
    "    rule_node = 'R' + str(i)\n",
    "    DiGraph.add_nodes_from([rule_node])\n",
    "    rule_nodes.add(rule_node)\n",
    "    lift = rules.iloc[i]['lift']\n",
    "    \n",
    "    # For antecedant, the arrow originates from antecedant to the Rule node\n",
    "    for antecedant in rules.iloc[i]['antecedants']:\n",
    "      DiGraph.add_nodes_from([antecedant])\n",
    "      DiGraph.add_edge(antecedant, rule_node, color=colors[i], weight=lift)\n",
    "    \n",
    "    # For consequent, the arrow originates fromt he Rule node to the consequent\n",
    "    for consequent in rules.iloc[i]['consequents']:\n",
    "      DiGraph.add_edge(rule_node, consequent, color=colors[i], weight=lift)\n",
    "  \n",
    "  # Set the color of rule nodes to orange, non-rule nodes to green\n",
    "  node_colors = ['orange' if node in rule_nodes else 'green'\n",
    "                 for node in DiGraph]\n",
    "  \n",
    "  # Print/draw results!\n",
    "  edges = DiGraph.edges()\n",
    "  nodes = DiGraph.nodes()\n",
    "  print('Nodes: ' + str(nodes))\n",
    "  print('Edges: ' + str(edges))\n",
    "  \n",
    "  edge_colors = [DiGraph[src][dest]['color'] for src, dest in edges]\n",
    "  edge_weights =  [DiGraph[src][dest]['weight'] for src, dest in edges]\n",
    "  \n",
    "  positions = netx.spring_layout(DiGraph, k=15, scale=1)\n",
    "  print(\"Node positions: \" + str(positions))\n",
    "  netx.draw_networkx(DiGraph, positions, edges=edges, node_color=node_colors,\n",
    "                    edge_color=edge_colors, width=edge_weights, font_size=16,\n",
    "                    with_labels=False)\n",
    "  \n",
    "  # Add labels under nodes\n",
    "  for position in positions:\n",
    "    positions[position][1] -= 0.15\n",
    "  netx.draw_networkx_labels(DiGraph, positions)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_country(country, min_support=0.10, lift_threshold=4):\n",
    "  \"\"\"Run associaton rule analysis for a given country.\"\"\"\n",
    "  transactions_per_row = df[df['Country'] == country].pivot_table(\n",
    "      index='InvoiceNo', columns='Description', values='Quantity',\n",
    "      aggfunc='sum', fill_value=0)\n",
    "  # Let's get rid of postage, it's not really a product\n",
    "  transactions_per_row.drop('POSTAGE', inplace=True, axis=1)\n",
    "  # Last bit of cleaning - we only care if a transaction includes an item or not\n",
    "  purchase_sets = transactions_per_row.applymap(\n",
    "      lambda quantity: 1 if quantity >= 1 else 0)\n",
    "  # Time for Apriori!\n",
    "  # Calculate support (indication of how frequently itemset appears in data)\n",
    "  # and confidence (indication of how often a rule is true)\n",
    "  frequent_itemsets = apriori(purchase_sets, min_support=min_support,\n",
    "                              use_colnames=True)\n",
    "  associationrules = association_rules(frequent_itemsets, metric='lift',\n",
    "                                       min_threshold=lift_threshold)\n",
    "  draw_association_graph(associationrules, associationrules.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_country('Belgium', min_support=0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_country('Germany', min_support=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git status && git add . && git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git commit -am \"integrated the functions from the lecture, so I have the Germany and Belgium graphed, now I need to try to make sense of the relationships and tweak the thresholds as well as the ?attributes? I manipulate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git status && git push && git status && date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Coding Challenge Association-Models.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
